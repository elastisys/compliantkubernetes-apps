{{- if and .Values.defaultRules.create .Values.defaultRules.rules.fluentd }}
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: {{ printf "%s-%s" (include "prometheus-alerts.fullname" .) "fluentd" | trunc 63 | trimSuffix "-" }}
  labels:
    app: {{ template "prometheus-alerts.fullname" . }}
{{ include "prometheus-alerts.labels" . | indent 4 }}
{{- if .Values.defaultRules.alertLabels }}
{{ toYaml .Values.defaultRules.alertLabels | indent 4 }}
{{- end }}
{{- if .Values.defaultRules.annotations }}
  annotations:
{{ toYaml .Values.defaultRules.annotations | indent 4 }}
{{- end }}
spec:
  groups:
  - name: fluentd
    rules:
    - alert: FluentdNodeDown
      expr: up{job=~"fluentd.*"} == 0
      for: 10m
      labels:
        service: fluentd
        severity: warning
      annotations:
        summary: fluentd cannot be scraped
        description: Prometheus could not scrape {{ "{{ $labels.job }}" }} for more than 10 minutes
    - alert: FluentdNodeDown
      expr: up{job=~"fluentd.*"} == 0
      for: 30m
      labels:
        service: fluentd
        severity: critical
      annotations:
        summary: fluentd cannot be scraped
        description: Prometheus could not scrape {{ "{{ $labels.job }}" }} for more than 30 minutes
    - alert: FluentdQueueLength
      expr: rate(fluentd_status_buffer_queue_length[5m]) > 0.3
      for: 1m
      labels:
        service: fluentd
        severity: warning
      annotations:
        summary: fluentd node are failing
        description: In the last 5 minutes, fluentd queues increased 30%. Current value is {{ "{{ $value }}" }}
    - alert: FluentdQueueLength
      expr: rate(fluentd_status_buffer_queue_length[5m]) > 0.5
      for: 1m
      labels:
        service: fluentd
        severity: critical
      annotations:
        summary: fluentd node are critical
        description: In the last 5 minutes, fluentd queues increased 50%. Current value is {{ "{{ $value }}" }}
    - alert: FluentdRecordsCountsHigh
      expr: >
        sum(rate(fluentd_output_status_emit_records{job="fluentd-metrics"}[5m]))
        BY (cluster, instance) >  (3 * sum(rate(fluentd_output_status_emit_records{job="fluentd-metrics"}[15m]))
        BY (cluster, instance))
      for: 10m
      labels:
        service: fluentd
        severity: warning
      annotations:
        summary: fluentd records count are critical
        description: In the last 5m, records counts increased 3 times, comparing to the latest 15 min.
    - alert: FluentdRetry
      expr: increase(fluentd_status_retry_count[10m]) > 0
      for: 20m
      labels:
        service: fluentd
        severity: warning
      annotations:
        description: Fluentd retry count has been  {{ "{{ $value }}" }} for the last 10 minutes
        summary: Fluentd retry count has been  {{ "{{ $value }}" }} for the last 10 minutes
    - alert: FluentdOutputError
      expr: increase(fluentd_output_status_num_errors[10m]) > 0
      for: 1s
      labels:
        service: fluentd
        severity: warning
      annotations:
        description: Fluentd output error count is {{ "{{ $value }}" }} for the last 10 minutes
        summary: There have been Fluentd output error(s) for the last 10 minutes
{{- end }}
