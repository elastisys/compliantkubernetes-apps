{{- if and .Values.defaultRules.create .Values.defaultRules.rules.capacityManagementAlerts}}
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: {{ printf "%s-%s" (include "prometheus-alerts.fullname" .) "cluster-capacity-management-alerts" | trunc 63 | trimSuffix "-" }}
  labels:
    app: {{ template "prometheus-alerts.name" . }}
{{ include "prometheus-alerts.labels" . | indent 4 }}
{{- if .Values.defaultRules.alertLabels }}
{{ toYaml .Values.defaultRules.alertLabels | indent 4 }}
{{- end }}
{{- if .Values.defaultRules.annotations }}
  annotations:
{{ toYaml .Values.defaultRules.annotations | indent 4 }}
{{- end }}
spec:
  groups:
  - name: cluster-capacity-management-alerts
    rules:
    - alert: NodeFilesystemSpaceFillingUp
      annotations:
        description: Filesystem on {{`{{`}} $labels.device {{`}}`}} at {{`{{`}} $labels.instance {{`}}`}} has only {{`{{`}} printf "%.2f" $value {{`}}`}}% available space left and is filling up.
        runbook_url: {{ .Values.defaultRules.runbookUrl }}alert-name-nodefilesystemspacefillingup
        summary: Filesystem is predicted to run out of space within the next 3 days.
      expr: |-
        (
          (node_filesystem_avail_bytes{job="node-exporter",fstype!=""} / node_filesystem_size_bytes{job="node-exporter",fstype!=""} * 100) < (100-{{ .Values.capacityManagementAlertsDiskLimit }})
        and
          predict_linear(node_filesystem_avail_bytes{job="node-exporter",fstype!=""}[6h], 3*24*60*60) <= (node_filesystem_size_bytes*(1-{{ .Values.capacityManagementAlertsDiskLimit }}/100))
        and
          node_filesystem_readonly{job="node-exporter",fstype!=""} == 0
        )
      for: 1h
      labels:
        severity: warning
    - alert: PersistentVolume{{.Values.capacityManagementAlertsDiskLimit}}PercentInThreeDays
      annotations:
        message: The PersistentVolume claimed by {{`{{ $labels.persistentvolumeclaim }}`}} in Namespace {{`{{ $labels.namespace }}`}} will go over {{.Values.capacityManagementAlertsDiskLimit}} in three days.
      expr: predict_linear(kubelet_volume_stats_available_bytes[24h], 3*24*60*60) <= (kubelet_volume_stats_capacity_bytes*(1-{{ .Values.capacityManagementAlertsDiskLimit }}/100))
      for: 5m
      labels:
        severity: warning
    - alert: Memory{{.Values.capacityManagementAlertsUsageLimit}}PercentInThreeDays
      annotations:
        message: Memory usage in Cluster {{`{{ $labels.cluster }}`}} Instance {{`{{ $labels.instance }}`}} is predicted to go over {{.Values.capacityManagementAlertsUsageLimit}}% within the next 3 days at current use rate.
      expr: predict_linear(node_memory_MemAvailable_bytes[24h], 3*24*60*60) <= (node_memory_MemTotal_bytes*(1-{{ .Values.capacityManagementAlertsUsageLimit }}/100))
      for: 5m
      labels:
        severity: warning
    - alert: CPU{{.Values.capacityManagementAlertsUsageLimit}}PercentOnAverage
      annotations:
        message: CPU usage has been over {{.Values.capacityManagementAlertsUsageLimit}}% on average over the span of 24h in a Instance {{`{{ $labels.instance }}`}} of a Cluster {{`{{ $labels.cluster }}`}}.
      expr: 1 - (avg by (instance, cluster) (rate(node_cpu_seconds_total{job="node-exporter",mode="idle"}[24h]))) >= {{ .Values.capacityManagementAlertsUsageLimit }}/100
      for: 5m
      labels:
        severity: warning
    {{- range $resource, $patterns := .Values.capacityManagementAlertsRequestLimit }}
    {{- range $pattern := $patterns }}
    - alert: {{ $resource | title }}Request{{ $pattern.limit }}Percent{{ $pattern.name | title }}
      annotations:
        message: {{ $resource | title }} request has been over {{ $pattern.limit }}% on {{ $pattern.name }} nodes in cluster {{`{{ $labels.cluster }}`}}.
      expr: sum by(cluster) (kube_pod_container_resource_requests{node=~"{{ $pattern.pattern }}",cluster=~".*",namespace=~".*",resource="{{ $resource }}"} and on(pod, namespace, cluster) kube_pod_status_phase{cluster=~".*",namespace=~".*",phase="Running"} == 1) / sum by(cluster) (kube_node_status_allocatable{node=~"{{ $pattern.pattern }}",cluster=~".*",resource="{{ $resource }}"}) >= {{ $pattern.limit }} / 100
      for: 5m
      labels:
        severity: warning
    {{- end }}
    {{- end }}
{{- end }}
