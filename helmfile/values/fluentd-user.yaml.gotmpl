resources:    {{- toYaml .Values.fluentd.user.resources | nindent 2  }}
nodeSelector: {{- toYaml .Values.fluentd.user.nodeSelector | nindent 2  }}
affinity:     {{- toYaml .Values.fluentd.user.affinity | nindent 2  }}
tolerations:  {{- toYaml .Values.fluentd.user.tolerations | nindent 2  }}

elasticsearch:
  scheme: https
  auth:
    enabled: true
    user: fluentd
    password: null
  hosts: ["elastic.{{ .Values.global.opsDomain }}"]
  sslVerify: {{ .Values.global.verifyTls }}
  logLevel: "info"

configMaps:
  useDefaults:
    systemConf: false
    containersInputConf: false
    outputConf: false

secret:
- name: OUTPUT_PASSWORD
  secret_name: elasticsearch
  secret_key: password

env:
  LIVENESS_THRESHOLD_SECONDS: 900
  STUCK_THRESHOLD_SECONDS: 1200
  OUTPUT_PORT: 443

extraConfigMaps:
  system.conf: |-
    <system>
      root_dir /tmp/fluentd-buffers/
      <log>
        format json
      </log>
    </system>

  containers.input.conf: |-
    #This config is taken from a default config that we have disabled
    #See the value "configMaps.useDefaults.containersInputConf: false" above
    #But we added "reserve_time true" in order to allow falco logs to use json
    <source>
      @id fluentd-containers.log
      @type tail
      path /var/log/containers/*.log
      pos_file /var/log/containers.log.pos
      tag raw.kubernetes.*
      read_from_head true
      <parse>
        @type multi_format
        <pattern>
          format json
          time_key time
          time_format %Y-%m-%dT%H:%M:%S.%NZ
        </pattern>
        <pattern>
          format /^(?<time>.+) (?<stream>stdout|stderr) [^ ]* (?<log>.*)$/
          time_format %Y-%m-%dT%H:%M:%S.%N%:z
        </pattern>
      </parse>
    </source>

    # Detect exceptions in the log output and forward them as one log entry.
    <match raw.kubernetes.**>
      @id raw.kubernetes
      @type detect_exceptions
      remove_tag_prefix raw
      message log
      stream stream
      multiline_flush_interval 5
      max_bytes 500000
      max_lines 1000
    </match>

    # Concatenate multi-line logs
    <filter **>
      @id filter_concat
      @type concat
      key log
      multiline_end_regexp /\n$/
      separator ""
    </filter>

    # Enriches records with Kubernetes metadata
    <filter kubernetes.**>
      @id filter_kubernetes_metadata
      @type kubernetes_metadata
    </filter>

    # Fixes json fields in Elasticsearch
    <filter kubernetes.**>
      @id filter_parser
      @type parser
      key_name log
      reserve_data true
      reserve_time true #This is the line that is changed from the default config
      remove_key_name_field true
      <parse>
        @type multi_format
        <pattern>
          format json
        </pattern>
        <pattern>
          format none
        </pattern>
      </parse>
    </filter>

    <filter **>
      @type record_transformer
      <record>
        cluster.name "{{ .Values.global.clusterName }}"
      </record>
    </filter>

    # Include extra configuration files
    @include /etc/fluent/extra-config.d/*.conf

  output.conf: |-
    <match kubeaudit.**>
        @id elasticsearch_kubeaudit
        @type elasticsearch
        @log_level "#{ENV['OUTPUT_LOG_LEVEL']}"
        include_tag_key true
        type_name _doc
        host "#{ENV['OUTPUT_HOSTS']}"
        port "#{ENV['OUTPUT_PORT']}"
        path "#{ENV['OUTPUT_PATH']}"
        scheme "#{ENV['OUTPUT_SCHEME']}"
        ssl_verify "#{ENV['OUTPUT_SSL_VERIFY']}"
        ssl_version "#{ENV['OUTPUT_SSL_VERSION']}"
        user "#{ENV['OUTPUT_USER']}"
        password "#{ENV['OUTPUT_PASSWORD']}"
        reconnect_on_error true
        # Custom parameters --START--
        reload_on_failure true
        reload_connections false
        include_timestamp true # defaults to false
        index_name kubeaudit
        default_elasticsearch_version 7
        # https://github.com/uken/fluent-plugin-elasticsearch/issues/785
        suppress_type_name true
        # Custom parameters --END--
        <buffer>
          @type file
          path /var/log/fluentd-buffers/kubernetes.kubeaudit.system.buffer
          flush_mode interval
          retry_type exponential_backoff
          flush_thread_count 2
          flush_interval 5s
          retry_forever
          retry_max_interval 30
          chunk_limit_size "#{ENV['OUTPUT_BUFFER_CHUNK_LIMIT']}"
          queue_limit_length "#{ENV['OUTPUT_BUFFER_QUEUE_LIMIT']}"
          overflow_action block
        </buffer>
    </match>
    <match kubernetes.**>
        @id elasticsearch_kubernetes
        @type elasticsearch
        @log_level "#{ENV['OUTPUT_LOG_LEVEL']}"
        include_tag_key true
        type_name _doc
        host "#{ENV['OUTPUT_HOSTS']}"
        port "#{ENV['OUTPUT_PORT']}"
        path "#{ENV['OUTPUT_PATH']}"
        scheme "#{ENV['OUTPUT_SCHEME']}"
        ssl_verify "#{ENV['OUTPUT_SSL_VERIFY']}"
        ssl_version "#{ENV['OUTPUT_SSL_VERSION']}"
        user "#{ENV['OUTPUT_USER']}"
        password "#{ENV['OUTPUT_PASSWORD']}"
        reconnect_on_error true
        # Custom parameters --START--
        reload_on_failure true
        reload_connections false
        include_timestamp true # defaults to false
        index_name kubernetes
        default_elasticsearch_version 7
        # https://github.com/uken/fluent-plugin-elasticsearch/issues/785
        suppress_type_name true
        # Custom parameters --END--
        <buffer>
          @type file
          path /var/log/fluentd-buffers/kubernetes.kubernetes.system.buffer
          flush_mode interval
          retry_type exponential_backoff
          flush_thread_count 2
          flush_interval 5s
          retry_forever
          retry_max_interval 30
          chunk_limit_size "#{ENV['OUTPUT_BUFFER_CHUNK_LIMIT']}"
          queue_limit_length "#{ENV['OUTPUT_BUFFER_QUEUE_LIMIT']}"
          overflow_action block
        </buffer>
    </match>
    <match **>
        @id elasticsearch
        @type elasticsearch
        @log_level "#{ENV['OUTPUT_LOG_LEVEL']}"
        include_tag_key true
        type_name _doc
        host "#{ENV['OUTPUT_HOSTS']}"
        port "#{ENV['OUTPUT_PORT']}"
        path "#{ENV['OUTPUT_PATH']}"
        scheme "#{ENV['OUTPUT_SCHEME']}"
        ssl_verify "#{ENV['OUTPUT_SSL_VERIFY']}"
        ssl_version "#{ENV['OUTPUT_SSL_VERSION']}"
        user "#{ENV['OUTPUT_USER']}"
        password "#{ENV['OUTPUT_PASSWORD']}"
        reconnect_on_error true
        # Custom parameters --START--
        reload_on_failure true
        reload_connections false
        include_timestamp true # defaults to false
        index_name other
        default_elasticsearch_version 7
        # https://github.com/uken/fluent-plugin-elasticsearch/issues/785
        suppress_type_name true
        # Custom parameters --END--
        <buffer>
          @type file
          path /var/log/fluentd-buffers/kubernetes.system.buffer
          flush_mode interval
          retry_type exponential_backoff
          flush_thread_count 2
          flush_interval 5s
          retry_forever
          retry_max_interval 30
          chunk_limit_size "#{ENV['OUTPUT_BUFFER_CHUNK_LIMIT']}"
          queue_limit_length "#{ENV['OUTPUT_BUFFER_QUEUE_LIMIT']}"
          overflow_action block
        </buffer>
      </match>

extraVolumes:
  - name: extra-config
    configMap:
      name: fluentd-extra-config
  - name: fluentd-extra-plugins
    configMap:
      defaultMode: 420
      name: fluentd-extra-plugins

extraVolumeMounts:
  - name: extra-config
    mountPath: /etc/fluent/extra-config.d
    readOnly: true
  - name: fluentd-extra-plugins
    mountPath: /etc/fluent/plugin
    readOnly: true

podSecurityPolicy:
  enabled: true
