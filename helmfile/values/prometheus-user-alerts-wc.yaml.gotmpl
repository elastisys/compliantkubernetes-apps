# Note: These values are used for setting up alerts for the *user*.

osNodeCount: 0
alertmanagerJob: alertmanager-operated
alertmanagerNamespace: alertmanager
prometheusJob: kube-prometheus-stack-prometheus
operatorJob: kube-prometheus-stack-operator

prometheusNamespace: monitoring

defaultRules:
  # TODO: Keeping current behavior, but this should probably default to false!
  create: true
  # labels:
  #   cluster: workload
  rules:
    alertmanager: {{ .Values.user.alertmanager.enabled }}
    # Rook is handled by the cluster operators. Users would normally not care
    # about these alerts, but we have no other way of gathering them currently.
    rookMonitor: {{ .Values.rookCeph.monitoring.enabled }}
    capacityManagementAlerts: {{ .Values.prometheus.capacityManagementAlerts.enabled }}
    networkpolicies: {{ .Values.networkPolicies.enableAlerting }}
    # handled by the platform administrator
    opensearch: false
    falcoAlerts: false # falco alerts will come from falco sidekick
    harbor: false
    missingMetrics: false # not useful for wc
    dns: false
    kubeProxy: false
    prometheusOperator: false
    network: false
    kubernetesSystem: false
    kubeStateMetrics: false


capacityManagementAlertsPersistentVolumeEnabled: {{ .Values.prometheus.capacityManagementAlerts.persistentVolume.enabled }}
capacityManagementAlertsPersistentVolumeLimit: {{ .Values.prometheus.capacityManagementAlerts.persistentVolume.limit }}
capacityManagementAlertsDiskLimit: {{ .Values.prometheus.capacityManagementAlerts.disklimit }}
capacityManagementAlertsUsageLimit: {{ .Values.prometheus.capacityManagementAlerts.usagelimit }}
capacityManagementAlertsRequestLimit:
{{ toYaml .Values.prometheus.capacityManagementAlerts.requestlimit | indent 2 }}
