resources:    {{- toYaml .Values.fluentd.resources | nindent 2  }}
nodeSelector: {{- toYaml .Values.fluentd.nodeSelector | nindent 2  }}
affinity:     {{- toYaml .Values.fluentd.affinity | nindent 2  }}
tolerations:  {{- toYaml .Values.fluentd.tolerations | nindent 2  }}

elasticsearch:
  scheme: https
  port: 443
  auth:
    enabled: true
    user: fluentd
    password: null
  hosts: ["{{ .Values.opensearch.subdomain }}.{{ .Values.global.opsDomain  }}"]
  sslVerify: {{ .Values.global.verifyTls }}
  logLevel: "info"
  reloadOnFailure: true
  log400Reason: true
  buffer: {{- toYaml .Values.fluentd.elasticsearch.buffer | nindent 4 }}

secret:
- name: OUTPUT_PASSWORD
  secret_name: opensearch
  secret_key: password

podSecurityPolicy:
  enabled: true

env:
  LIVENESS_THRESHOLD_SECONDS: 900
  STUCK_THRESHOLD_SECONDS: 1200
  OUTPUT_PORT: 443
  OUTPUT_BUFFER_TOTAL_LIMIT: 20G

serviceMonitor:
  enabled: true

prometheusRule:
  enabled: true

# Default args include "-q" which sets loglevel to warning.
fluentdArgs: "--no-supervisor -q"
configMaps:
  useDefaults:
    systemConf: false
    containersInputConf: false
    outputConf: false
    monitoringConf: false

extraConfigMaps:
  system.conf: |-
    <system>
      root_dir /tmp/fluentd-buffers/
      <log>
        format json
      </log>
    </system>

  10-monitoring.conf: |-
    # Prometheus Exporter Plugin
    # input plugin that exports metrics
    <source>
      @id prometheus
      @type prometheus
    </source>

    # input plugin that collects metrics from MonitorAgent
    <source>
      @id prometheus_monitor
      @type prometheus_monitor
      <labels>
        host ${hostname}
      </labels>
    </source>

    # input plugin that collects metrics for output plugin
    <source>
      @id prometheus_output_monitor
      @type prometheus_output_monitor
      <labels>
        host ${hostname}
      </labels>
    </source>

    # Don't include prometheus_tail_monitor since this will cause number of metrics to increase indefinitely
    # https://github.com/fluent/fluent-plugin-prometheus/issues/20

  10-kube-audit.conf: |-
    <source>
      @id kube-audit
      @type tail
      path /var/log/kube-audit/kube-apiserver.log,/var/log/kubernetes/audit/kube-apiserver-audit.log
      pos_file /var/log/kube-audit/fluentd-kube-apiserver.pos
      pos_file_compaction_interval 72h
      tag kubeaudit.*
      read_from_head true
      skip_refresh_on_startup true
      <parse>
        @type multi_format
        <pattern>
          format json
          time_key requestReceivedTimestamp
          time_format %Y-%m-%dT%H:%M:%S.%NZ
        </pattern>
      </parse>
    </source>
    # Remove keys that include raw data causing errors
    # See: https://github.com/uken/fluent-plugin-elasticsearch/issues/452
    <filter kubeaudit.**>
      @id kube_api_audit_normalize
      @type record_transformer
      remove_keys responseObject,requestObject
    </filter>
    # Index the authlog
    <source>
      @id authlog
      @type tail
      path /var/log/auth.log
      pos_file /var/log/auth.pos
      pos_file_compaction_interval 72h
      tag authlog.*
      skip_refresh_on_startup true
      <parse>
        @type regexp
        expression /^(?<time>[^ ]* {1,2}[^ ]* [^ ]*) (?<host>[^ ]*) (?<ident>[a-zA-Z0-9_\/\.\-]*)(?:\[(?<pid>[0-9]+)\])?(?:[^\:]*\:)? *(?<message>.*)$/
      </parse>
    </source>

  containers.input.conf: |-
    #This config is taken from a default config that we have disabled
    #See the value "configMaps.useDefaults.containersInputConf: false" above
    #But we added "reserve_time true" in order to allow falco logs to use json
    <source>
      @id fluentd-containers.log
      @type tail
      path /var/log/containers/*.log
      pos_file /var/log/containers.log.pos
      pos_file_compaction_interval 72h
      tag raw.kubernetes.*
      read_from_head true
      skip_refresh_on_startup true
      <parse>
        @type multi_format
        <pattern>
          format json
          time_key time
          time_format %Y-%m-%dT%H:%M:%S.%NZ
        </pattern>
        <pattern>
          format /^(?<time>.+) (?<stream>stdout|stderr) (?<logtag>[^ ]*) (?<log>.*)$/
          time_format %Y-%m-%dT%H:%M:%S.%N%:z
        </pattern>
      </parse>
    </source>

    # Detect exceptions in the log output and forward them as one log entry.
    <match raw.kubernetes.**>
      @id raw.kubernetes
      @type detect_exceptions
      remove_tag_prefix raw
      message log
      stream stream
      multiline_flush_interval 5
      max_bytes 500000
      max_lines 1000
    </match>

    {{- if eq .Values.global.containerRuntime "docker" }}
    # Concatenate multi-line logs
    <filter **>
      @id filter_concat
      @type concat
      key log
      multiline_end_regexp /\n$/
      separator ""
    </filter>
    {{- else if eq .Values.global.containerRuntime "containerd" }}
    # Concatenate multi-line logs
    <filter **>
      @id filter_concat
      @type concat
      key message
      use_first_timestamp true
      partial_key logtag
      partial_value P
      separator ""
      # TODO: When we have updated this plugin to v2.5.0 change to this instead
      # @id filter_concat
      # @type concat
      # key message
      # use_partial_cri_logtag true
      # partial_cri_logtag_key logtag
      # partial_cri_stream_key stream
    </filter>
    {{- else }}
      {{ fail "Misconfigured `global.containerRuntime`. Supported container runtimes are 'containerd' and 'docker'" }}
    {{- end }}

    # Enriches records with Kubernetes metadata
    <filter kubernetes.**>
      @id filter_kubernetes_metadata
      @type kubernetes_metadata
    </filter>

    # Fixes json fields in Elasticsearch
    <filter kubernetes.**>
      @id filter_parser
      @type parser
      key_name log
      reserve_data true
      reserve_time true #This is the line that is changed from the default config
      remove_key_name_field true
      <parse>
        @type multi_format
        <pattern>
          format json
        </pattern>
        <pattern>
          format none
        </pattern>
      </parse>
    </filter>

    <filter **>
      @type record_transformer
      <record>
        cluster.name "{{ .Values.global.clusterName }}"
      </record>
    </filter>

  output.conf: |-
    <match authlog.**>
      @id elasticsearch_authlog
      @type "#{ENV['OUTPUT_TYPE']}"
      @log_level "#{ENV['OUTPUT_LOG_LEVEL']}"
      include_tag_key "#{ENV['OUTPUT_INCLUDE_TAG_KEY']}"
      type_name "#{ENV['OUTPUT_TYPE_NAME']}"
      hosts "#{ENV['OUTPUT_HOSTS']}"
      port "#{ENV['OUTPUT_PORT']}"
      path "#{ENV['OUTPUT_PATH']}"
      scheme "#{ENV['OUTPUT_SCHEME']}"
      ssl_verify "#{ENV['OUTPUT_SSL_VERIFY']}"
      ssl_version "#{ENV['OUTPUT_SSL_VERSION']}"
      user "#{ENV['OUTPUT_USER']}"
      password "#{ENV['OUTPUT_PASSWORD']}"
      log_es_400_reason "#{ENV['OUTPUT_LOG_400_REASON']}"
      reconnect_on_error "#{ENV['OUTPUT_RECONNECT_ON_ERROR']}"
      reload_on_failure "#{ENV['OUTPUT_RELOAD_ON_FAILURE']}"
      reload_connections "#{ENV['OUTPUT_RELOAD_CONNECTIONS']}"
      request_timeout "#{ENV['OUTPUT_REQUEST_TIMEOUT']}"

      # Custom parameters --START--
      include_timestamp true # defaults to false
      index_name authlog
      default_elasticsearch_version 7
      # https://github.com/uken/fluent-plugin-elasticsearch/issues/785
      suppress_type_name true
      # Custom parameters --END--

      <buffer>
        @type "#{ENV['OUTPUT_BUFFER_TYPE']}"
        path /var/log/fluentd-buffers/kubernetes.authlog.system.buffer
        flush_mode "#{ENV['OUTPUT_BUFFER_FLUSH_MODE']}"
        retry_type "#{ENV['OUTPUT_BUFFER_RETRY_TYPE']}"
        flush_thread_count "#{ENV['OUTPUT_BUFFER_FLUSH_THREAD_TYPE']}"
        flush_interval "#{ENV['OUTPUT_BUFFER_FLUSH_INTERVAL']}"
        retry_forever "#{ENV['OUTPUT_BUFFER_RETRY_FOREVER']}"
        retry_max_interval "#{ENV['OUTPUT_BUFFER_RETRY_MAX_INTERVAL']}"
        chunk_limit_size "#{ENV['OUTPUT_BUFFER_CHUNK_LIMIT']}"
        total_limit_size "#{ENV['OUTPUT_BUFFER_TOTAL_LIMIT']}"
        overflow_action "#{ENV['OUTPUT_BUFFER_OVERFLOW_ACTION']}"
      </buffer>
    </match>
    <match kubeaudit.**>
      @id elasticsearch_kubeaudit
      @type "#{ENV['OUTPUT_TYPE']}"
      @log_level "#{ENV['OUTPUT_LOG_LEVEL']}"
      include_tag_key "#{ENV['OUTPUT_INCLUDE_TAG_KEY']}"
      type_name "#{ENV['OUTPUT_TYPE_NAME']}"
      hosts "#{ENV['OUTPUT_HOSTS']}"
      port "#{ENV['OUTPUT_PORT']}"
      path "#{ENV['OUTPUT_PATH']}"
      scheme "#{ENV['OUTPUT_SCHEME']}"
      ssl_verify "#{ENV['OUTPUT_SSL_VERIFY']}"
      ssl_version "#{ENV['OUTPUT_SSL_VERSION']}"
      user "#{ENV['OUTPUT_USER']}"
      password "#{ENV['OUTPUT_PASSWORD']}"
      log_es_400_reason "#{ENV['OUTPUT_LOG_400_REASON']}"
      reconnect_on_error "#{ENV['OUTPUT_RECONNECT_ON_ERROR']}"
      reload_on_failure "#{ENV['OUTPUT_RELOAD_ON_FAILURE']}"
      reload_connections "#{ENV['OUTPUT_RELOAD_CONNECTIONS']}"
      request_timeout "#{ENV['OUTPUT_REQUEST_TIMEOUT']}"

      # Custom parameters --START--
      include_timestamp true # defaults to false
      index_name kubeaudit
      default_elasticsearch_version 7
      # https://github.com/uken/fluent-plugin-elasticsearch/issues/785
      suppress_type_name true
      # Custom parameters --END--

      <buffer>
        @type "#{ENV['OUTPUT_BUFFER_TYPE']}"
        path /var/log/fluentd-buffers/kubernetes.kubeaudit.system.buffer
        flush_mode "#{ENV['OUTPUT_BUFFER_FLUSH_MODE']}"
        retry_type "#{ENV['OUTPUT_BUFFER_RETRY_TYPE']}"
        flush_thread_count "#{ENV['OUTPUT_BUFFER_FLUSH_THREAD_TYPE']}"
        flush_interval "#{ENV['OUTPUT_BUFFER_FLUSH_INTERVAL']}"
        retry_forever "#{ENV['OUTPUT_BUFFER_RETRY_FOREVER']}"
        retry_max_interval "#{ENV['OUTPUT_BUFFER_RETRY_MAX_INTERVAL']}"
        chunk_limit_size "#{ENV['OUTPUT_BUFFER_CHUNK_LIMIT']}"
        total_limit_size "#{ENV['OUTPUT_BUFFER_TOTAL_LIMIT']}"
        overflow_action "#{ENV['OUTPUT_BUFFER_OVERFLOW_ACTION']}"
      </buffer>
    </match>
    <match kubernetes.**>
      @id elasticsearch_kubernetes
      {{- if .Values.opensearch.indexPerNamespace }}
      @type elasticsearch_dynamic
      {{- else }}
      @type "#{ENV['OUTPUT_TYPE']}"
      {{- end }}
      @log_level "#{ENV['OUTPUT_LOG_LEVEL']}"
      include_tag_key "#{ENV['OUTPUT_INCLUDE_TAG_KEY']}"
      type_name "#{ENV['OUTPUT_TYPE_NAME']}"
      hosts "#{ENV['OUTPUT_HOSTS']}"
      port "#{ENV['OUTPUT_PORT']}"
      path "#{ENV['OUTPUT_PATH']}"
      scheme "#{ENV['OUTPUT_SCHEME']}"
      ssl_verify "#{ENV['OUTPUT_SSL_VERIFY']}"
      ssl_version "#{ENV['OUTPUT_SSL_VERSION']}"
      user "#{ENV['OUTPUT_USER']}"
      password "#{ENV['OUTPUT_PASSWORD']}"
      log_es_400_reason "#{ENV['OUTPUT_LOG_400_REASON']}"
      reconnect_on_error "#{ENV['OUTPUT_RECONNECT_ON_ERROR']}"
      reload_on_failure "#{ENV['OUTPUT_RELOAD_ON_FAILURE']}"
      reload_connections "#{ENV['OUTPUT_RELOAD_CONNECTIONS']}"
      request_timeout "#{ENV['OUTPUT_REQUEST_TIMEOUT']}"

      # Custom parameters --START--
      include_timestamp true # defaults to false
      {{- if .Values.opensearch.indexPerNamespace }}
      logstash_format true
      logstash_prefix ${record['kubernetes']['namespace_name']}
      {{- else }}
      index_name kubernetes
      {{- end }}
      default_elasticsearch_version 7
      # https://github.com/uken/fluent-plugin-elasticsearch/issues/785
      suppress_type_name true
      # Custom parameters --END--

      <buffer>
        @type "#{ENV['OUTPUT_BUFFER_TYPE']}"
        path /var/log/fluentd-buffers/kubernetes.kubernetes.system.buffer
        flush_mode "#{ENV['OUTPUT_BUFFER_FLUSH_MODE']}"
        retry_type "#{ENV['OUTPUT_BUFFER_RETRY_TYPE']}"
        flush_thread_count "#{ENV['OUTPUT_BUFFER_FLUSH_THREAD_TYPE']}"
        flush_interval "#{ENV['OUTPUT_BUFFER_FLUSH_INTERVAL']}"
        retry_forever "#{ENV['OUTPUT_BUFFER_RETRY_FOREVER']}"
        retry_max_interval "#{ENV['OUTPUT_BUFFER_RETRY_MAX_INTERVAL']}"
        chunk_limit_size "#{ENV['OUTPUT_BUFFER_CHUNK_LIMIT']}"
        total_limit_size "#{ENV['OUTPUT_BUFFER_TOTAL_LIMIT']}"
        overflow_action "#{ENV['OUTPUT_BUFFER_OVERFLOW_ACTION']}"
      </buffer>
    </match>
    <match **>
      @id elasticsearch
      @type "#{ENV['OUTPUT_TYPE']}"
      @log_level "#{ENV['OUTPUT_LOG_LEVEL']}"
      include_tag_key "#{ENV['OUTPUT_INCLUDE_TAG_KEY']}"
      type_name "#{ENV['OUTPUT_TYPE_NAME']}"
      hosts "#{ENV['OUTPUT_HOSTS']}"
      port "#{ENV['OUTPUT_PORT']}"
      path "#{ENV['OUTPUT_PATH']}"
      scheme "#{ENV['OUTPUT_SCHEME']}"
      ssl_verify "#{ENV['OUTPUT_SSL_VERIFY']}"
      ssl_version "#{ENV['OUTPUT_SSL_VERSION']}"
      user "#{ENV['OUTPUT_USER']}"
      password "#{ENV['OUTPUT_PASSWORD']}"
      log_es_400_reason "#{ENV['OUTPUT_LOG_400_REASON']}"
      reconnect_on_error "#{ENV['OUTPUT_RECONNECT_ON_ERROR']}"
      reload_on_failure "#{ENV['OUTPUT_RELOAD_ON_FAILURE']}"
      reload_connections "#{ENV['OUTPUT_RELOAD_CONNECTIONS']}"
      request_timeout "#{ENV['OUTPUT_REQUEST_TIMEOUT']}"

      # Custom parameters --START--
      include_timestamp true # defaults to false
      index_name other
      default_elasticsearch_version 7
      # https://github.com/uken/fluent-plugin-elasticsearch/issues/785
      suppress_type_name true
      # Custom parameters --END--

      <buffer>
        @type "#{ENV['OUTPUT_BUFFER_TYPE']}"
        path /var/log/fluentd-buffers/kubernetes.system.buffer
        flush_mode "#{ENV['OUTPUT_BUFFER_FLUSH_MODE']}"
        retry_type "#{ENV['OUTPUT_BUFFER_RETRY_TYPE']}"
        flush_thread_count "#{ENV['OUTPUT_BUFFER_FLUSH_THREAD_TYPE']}"
        flush_interval "#{ENV['OUTPUT_BUFFER_FLUSH_INTERVAL']}"
        retry_forever "#{ENV['OUTPUT_BUFFER_RETRY_FOREVER']}"
        retry_max_interval "#{ENV['OUTPUT_BUFFER_RETRY_MAX_INTERVAL']}"
        chunk_limit_size "#{ENV['OUTPUT_BUFFER_CHUNK_LIMIT']}"
        total_limit_size "#{ENV['OUTPUT_BUFFER_TOTAL_LIMIT']}"
        overflow_action "#{ENV['OUTPUT_BUFFER_OVERFLOW_ACTION']}"
      </buffer>
    </match>

{{- range $key, $value := .Values.fluentd.extraConfigMaps }}
{{ $key | indent 2 }}: |-
{{ $value | indent 4 }}
{{- end }}
