{{ if not (or (eq .Values.objectStorage.type "s3") (eq .Values.objectStorage.type "gcs") (eq .Values.objectStorage.type "azure") ) }}
{{ fail "\nERROR: Velero requires s3 or gcs or azure object storage, see Values.objectStorage.type" }}
{{ end }}
resources:    {{- toYaml .Values.velero.resources | nindent 2  }}
tolerations:  {{- toYaml .Values.velero.tolerations | nindent 2  }}
nodeSelector: {{- toYaml .Values.velero.nodeSelector | nindent 2  }}

initContainers:
  {{- if eq .Values.objectStorage.type "s3" }}
  - name: velero-plugin-for-aws
    image: velero/velero-plugin-for-aws:v1.5.1
    imagePullPolicy: IfNotPresent
    securityContext:
      allowPrivilegeEscalation: false
      runAsNonRoot: true
      runAsGroup: 10000
      runAsUser: 10000
    volumeMounts:
      - mountPath: /target
        name: plugins
  {{- else if eq .Values.objectStorage.type "gcs" }}
  - name: velero-plugin-for-gcs
    image: velero/velero-plugin-for-gcp:v1.5.1
    imagePullPolicy: IfNotPresent
    securityContext:
      allowPrivilegeEscalation: false
      runAsNonRoot: true
      runAsGroup: 10000
      runAsUser: 10000
    volumeMounts:
      - mountPath: /target
        name: plugins
  {{- end }}

configuration:
  defaultVolumesToFsBackup: true

  # https://velero.io/docs/v1.11/api-types/backupstoragelocation/
  backupStorageLocation:
    - bucket: {{ .Values.objectStorage.buckets.velero }}
      prefix: service-cluster
      {{- if eq .Values.objectStorage.type "s3" }}
      provider: aws
      config:
        region: {{ .Values.objectStorage.s3.region }}
        s3ForcePathStyle: {{ .Values.objectStorage.s3.forcePathStyle }}
        s3Url: {{ .Values.objectStorage.s3.regionEndpoint }}
      {{- else if eq .Values.objectStorage.type "gcs" }}
      provider: gcp
      {{- else if eq .Values.objectStorage.type "azure" }}
      provider: azure
      config:
        resourceGroup: {{ .Values.objectStorage.azure.resourceGroup }}
        storageAccount: {{ .Values.objectStorage.azure.storageAccountName }}
        storageAccountKeyEnvVar: AZURE_STORAGE_ACCOUNT_ACCESS_KEY
      {{- end }}

credentials:
  # Create secret with credentials
  secretContents:
    cloud: |
    {{- if eq .Values.objectStorage.type "s3" }}
      [default]
      aws_access_key_id: {{ .Values.objectStorage.s3.accessKey }}
      aws_secret_access_key: {{ .Values.objectStorage.s3.secretKey }}
    {{- else if eq .Values.objectStorage.type "gcs" }}
      {{ .Values.objectStorage.gcs.keyfileData | nindent 6 }}
    {{- else if eq .Values.objectStorage.type "azure" }}
      AZURE_STORAGE_ACCOUNT_ACCESS_KEY={{ .Values.objectStorage.azure.storageAccountKey }}
      AZURE_CLOUD_NAME=AzurePublicCloud
    {{- end }}

deployNodeAgent: true

nodeAgent:
  resources:   {{- toYaml .Values.velero.nodeAgent.resources | nindent 4  }}
  tolerations: {{- toYaml .Values.velero.nodeAgent.tolerations | nindent 4  }}

  privileged: true

  containerSecurityContext:
    runAsUser: 0
    allowPrivilegeEscalation: true

schedules:
  daily-backup:
    schedule: {{ .Values.velero.schedule }}
    template:
      storageLocation: default
      labelSelector:
        matchLabels:
          velero: backup
      excludedResources:
        - clustercompliancereports.aquasecurity.github.io
        - clusterconfigauditreports.aquasecurity.github.io
        - clusterinfraassessmentreports.aquasecurity.github.io
        - clusterrbacassessmentreports.aquasecurity.github.io
        - clustersbomreports.aquasecurity.github.io
        - configauditreports.aquasecurity.github.io
        - exposedsecretreports.aquasecurity.github.io
        - infraassessmentreports.aquasecurity.github.io
        - rbacassessmentreports.aquasecurity.github.io
        - sbomreports.aquasecurity.github.io
        - vulnerabilityreports.aquasecurity.github.io
      ttl: {{ .Values.velero.retentionPeriod }}

metrics:
  enabled: true
  scrapeInterval: 30s

  serviceMonitor:
    enabled: true

# For velero containers
containerSecurityContext:
  allowPrivilegeEscalation: false
  runAsNonRoot: true
  runAsGroup: 10000
  runAsUser: 10000

# For kubectl containers
kubectl:
  containerSecurityContext:
    allowPrivilegeEscalation: false
    runAsNonRoot: true
    runAsGroup: 10000
    runAsUser: 10000

# This job upgrades the CRDs.
upgradeCRDs: false

# Run velero-restore-helper init container with numeric UID and GID.
configMaps:
  restore-helper-config:
    labels:
      velero.io/plugin-config: ""
      velero.io/pod-volume-restore: RestoreItemAction
    data:
      secCtxRunAsUser: "1000"
      secCtxRunAsGroup: "1000"
