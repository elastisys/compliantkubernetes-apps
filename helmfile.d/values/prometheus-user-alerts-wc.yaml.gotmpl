# Note: These values are used for setting up alerts for the *user*.

# Get and transform autoscaledNodeGroupAlerts label and values
{{- $groupLabel := .Values.prometheus.autoscaledNodeGroupAlerts.groupLabel -}}
{{- $transformedGroupLabel := $groupLabel | replace "." "_" | replace "/" "_" | replace "-" "_" -}}
{{- $groupLabel := printf "label_%s" $transformedGroupLabel -}}

{{- $groupLabelValueArray := .Values.prometheus.autoscaledNodeGroupAlerts.groupLabelValues -}}
{{- $groupLabelValueArrayRegex := join "|" $groupLabelValueArray -}}

osMaxShardsPerNode: 0
osDataNodeCount: 0
osNodeCount: 0
alertmanagerJob: alertmanager-operated
alertmanagerNamespace: alertmanager
prometheusJob: kube-prometheus-stack-prometheus
operatorJob: kube-prometheus-stack-operator

prometheusNamespace: monitoring

defaultRules:
  # TODO: Keeping current behavior, but this should probably default to false!
  create: true
  # labels:
  #   cluster: workload
  rules:
    opensearch: false
    falcoAlerts: false # falco alerts will come from falco sidekick
    alertmanager: {{ .Values.prometheus.devAlertmanager.enabled }}
    # Rook is handled by the cluster operators. Users would normally not care
    # about these alerts, but we have no other way of gathering them currently.
    rookMonitor: {{ .Values.rookCeph.monitoring.enabled }}
    capacityManagementAlerts: {{ .Values.prometheus.capacityManagementAlerts.enabled }}
    networkpolicies: {{ .Values.networkPolicies.enableAlerting }}
    harbor: false
    webhooks: {{ .Values.prometheus.webhookAlerts.enabled }}
    kured: false

capacityManagementAlertsPersistentVolumeEnabled: {{ .Values.prometheus.capacityManagementAlerts.persistentVolume.enabled }}
capacityManagementAlertsPersistentVolumeLimit: {{ .Values.prometheus.capacityManagementAlerts.persistentVolume.limit }}
capacityManagementAlertsDiskLimit: {{ .Values.prometheus.capacityManagementAlerts.disklimit }}
capacityManagementAlertsPredictUsage: {{ .Values.prometheus.capacityManagementAlerts.predictUsage }}
capacityManagementAlertsUsageLimit: {{ .Values.prometheus.capacityManagementAlerts.usagelimit }}
capacityManagementAlertsRequestLimit:
{{ toYaml .Values.prometheus.capacityManagementAlerts.requestLimit.cpu | indent 2 }}
capacityManagementAlertsMemoryRequestLimit:
{{ toYaml .Values.prometheus.capacityManagementAlerts.requestLimit.memory | nindent 2 }}
capacityManagementAlertsRequestsExcludePattern: {{ .Values.prometheus.capacityManagementAlerts.nodeGroupRequestsExcludePattern }}
capacityManagementAlertsNodeGroupCpuLimit24h: {{ .Values.prometheus.capacityManagementAlerts.nodeGroupCpuLimit24h }}
capacityManagementAlertsNodeGroupMemoryLimit24h: {{ .Values.prometheus.capacityManagementAlerts.nodeGroupMemoryLimit24h }}
capacityManagementAlertsNodeGroupCpuLimit1h: {{ .Values.prometheus.capacityManagementAlerts.nodeGroupCpuLimit1h }}
capacityManagementAlertsNodeGroupMemoryLimit1h: {{ .Values.prometheus.capacityManagementAlerts.nodeGroupMemoryLimit1h }}
capacityManagementAlertsNodeCpuLimit1h: {{ .Values.prometheus.capacityManagementAlerts.nodeCpuLimit1h }}
capacityManagementAlertsNodeMemoryLimit1h: {{ .Values.prometheus.capacityManagementAlerts.nodeMemoryLimit1h }}

autoscaledNodeGroupAlerts:
  enabled: {{ .Values.prometheus.autoscaledNodeGroupAlerts.enabled }}
  groupLabel: {{ $groupLabel }}
  {{- if $groupLabelValueArrayRegex }}
  groupLabelValue:
    regex: '=~"{{ $groupLabelValueArrayRegex }}"'
  {{- else }}
  groupLabelValue:
    regex: '!=""'
  {{- end }}
