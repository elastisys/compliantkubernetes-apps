{{- if and .Values.defaultRules.create .Values.defaultRules.rules.capacityManagementAlerts}}
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: {{ printf "%s-%s" (include "prometheus-alerts.fullname" .) "cluster-capacity-management-alerts" | trunc 63 | trimSuffix "-" }}
  labels:
    app: {{ template "prometheus-alerts.name" . }}
{{ include "prometheus-alerts.labels" . | indent 4 }}
{{- if .Values.defaultRules.alertLabels }}
{{ toYaml .Values.defaultRules.alertLabels | indent 4 }}
{{- end }}
{{- if .Values.defaultRules.annotations }}
  annotations:
{{ toYaml .Values.defaultRules.annotations | indent 4 }}
{{- end }}
spec:
  groups:
  - name: cluster-capacity-management-alerts
    rules:
    - alert: NodeFilesystemSpaceFillingUp
      annotations:
        description: Filesystem on {{`{{`}} $labels.device {{`}}`}} at {{`{{`}} $labels.instance {{`}}`}} has only {{`{{`}} printf "%.2f" $value {{`}}`}}% available space left and is filling up.
        runbook_url: {{ .Values.runbookUrls.clusterCapacityManagement.NodeFilesystemSpaceFillingUp }}
        summary: Filesystem is predicted to run out of space within the next 3 days.
      expr: |-
        (
          (node_filesystem_avail_bytes{job="node-exporter",fstype!=""} / node_filesystem_size_bytes{job="node-exporter",fstype!=""} * 100) < (100-{{ .Values.capacityManagementAlertsDiskLimit }})
        and
          predict_linear(node_filesystem_avail_bytes{job="node-exporter",fstype!=""}[6h], 3*24*60*60) <= (node_filesystem_size_bytes*(1-{{ .Values.capacityManagementAlertsDiskLimit }}/100))
        and
          node_filesystem_readonly{job="node-exporter",fstype!=""} == 0
        )
      for: 1h
      labels:
        severity: warning
    {{- if .Values.capacityManagementAlertsPersistentVolumeEnabled }}
    - alert: PersistentVolume{{.Values.capacityManagementAlertsPersistentVolumeLimit}}PercentInThreeDays
      annotations:
        message: The PersistentVolume claimed by {{`{{ $labels.persistentvolumeclaim }}`}} in Namespace {{`{{ $labels.namespace }}`}} will go over {{.Values.capacityManagementAlertsPersistentVolumeLimit}} in three days.
        runbook_url: {{ .Values.runbookUrls.clusterCapacityManagement.PersistentVolumeXPercentInThreeDays }}
      expr: predict_linear(kubelet_volume_stats_available_bytes[24h], 3*24*60*60) <= (kubelet_volume_stats_capacity_bytes*(1-{{ .Values.capacityManagementAlertsPersistentVolumeLimit }}/100))
      for: 5m
      labels:
        severity: warning
    {{- end }}
    {{- if .Values.capacityManagementAlertsPredictUsage}}
    - alert: Memory{{.Values.capacityManagementAlertsUsageLimit}}PercentInThreeDays
      annotations:
        message: Memory usage in Cluster {{`{{ $labels.cluster }}`}} Instance {{`{{ $labels.instance }}`}} is predicted to go over {{.Values.capacityManagementAlertsUsageLimit}}% within the next 3 days at current use rate.
        runbook_url: {{ .Values.runbookUrls.clusterCapacityManagement.MemoryXPercentInThreeDays }}
      expr: predict_linear(node_memory_MemAvailable_bytes[24h], 3*24*60*60) <= (node_memory_MemTotal_bytes*(1-{{ .Values.capacityManagementAlertsUsageLimit }}/100))
      for: 5m
      labels:
        severity: warning
    {{- end }}
    - alert: NodeGroupCPU{{.Values.capacityManagementAlertsNodeGroupCpuLimit24h}}PercentOver24h
      annotations:
        message: CPU usage has been over {{.Values.capacityManagementAlertsNodeGroupCpuLimit24h}}% on average over the span of 24h in the Node Group {{`{{ $labels.label_elastisys_io_node_group }}`}} in Cluster {{`{{ $labels.cluster }}`}}.
        runbook_url: {{ .Values.runbookUrls.clusterCapacityManagement.NodeGroupCPUXPercentOver24h }}
      expr: avg by (label_elastisys_io_node_group,cluster) (sum by (instance) (rate(node_cpu_seconds_total{mode!='idle',cluster=~".*"}[24h])) / on (instance) instance:node_num_cpu:sum * on (instance) group_left (label_elastisys_io_node_group,cluster) label_replace(kube_node_labels{label_elastisys_io_node_group!=""}, "instance", "$1", "node", "(.*)")) > {{.Values.capacityManagementAlertsNodeGroupCpuLimit24h}}/100
      for: 5m
      labels:
        severity: warning
    - alert: NodeGroupCPU{{.Values.capacityManagementAlertsNodeGroupCpuLimit1h}}PercentOver1h
      annotations:
        message: CPU usage has been over {{.Values.capacityManagementAlertsNodeGroupCpuLimit1h}}% on average over the span of 1h in the Node Group {{`{{ $labels.label_elastisys_io_node_group }}`}} in Cluster {{`{{ $labels.cluster }}`}}.
        runbook_url: {{ .Values.runbookUrls.clusterCapacityManagement.NodeGroupCPUXPercentOver1h }}
      expr: avg by (label_elastisys_io_node_group,cluster) (sum by (instance) (rate(node_cpu_seconds_total{mode!='idle',cluster=~".*"}[1h])) / on (instance) instance:node_num_cpu:sum * on (instance) group_left (label_elastisys_io_node_group,cluster) label_replace(kube_node_labels{label_elastisys_io_node_group!=""}, "instance", "$1", "node", "(.*)")) > {{.Values.capacityManagementAlertsNodeGroupCpuLimit1h}}/100
      for: 5m
      labels:
        severity: warning
    - alert: NodeGroupMemory{{.Values.capacityManagementAlertsNodeGroupMemoryLimit24h}}PercentOver24h
      annotations:
        message: Memory usage has been over {{.Values.capacityManagementAlertsNodeGroupMemoryLimit24h}}% on average over the span of 24h in the Node Group {{`{{ $labels.label_elastisys_io_node_group }}`}} in Cluster {{`{{ $labels.cluster }}`}}.
        runbook_url: {{ .Values.runbookUrls.clusterCapacityManagement.NodeGroupMemoryXPercentOver24h }}
      expr: avg by (label_elastisys_io_node_group,cluster) ((avg_over_time (instance:node_memory_utilisation:ratio{cluster=~".*"}[24h])) * on (instance) group_left (label_elastisys_io_node_group) label_replace(kube_node_labels{label_elastisys_io_node_group!=""}, "instance", "$1", "node", "(.*)")) > {{.Values.capacityManagementAlertsNodeGroupMemoryLimit24h}}/100
      for: 5m
      labels:
        severity: warning
    - alert: NodeGroupMemory{{.Values.capacityManagementAlertsNodeGroupMemoryLimit1h}}PercentOver1h
      annotations:
        message: Memory usage has been over {{.Values.capacityManagementAlertsNodeGroupMemoryLimit1h}}% on average over the span of 1h in the Node Group {{`{{ $labels.label_elastisys_io_node_group }}`}} in Cluster {{`{{ $labels.cluster }}`}}.
        runbook_url: {{ .Values.runbookUrls.clusterCapacityManagement.NodeGroupMemoryXPercentOver1h }}
      expr: avg by (label_elastisys_io_node_group,cluster) ((avg_over_time (instance:node_memory_utilisation:ratio{cluster=~".*"}[1h])) * on (instance) group_left (label_elastisys_io_node_group) label_replace(kube_node_labels{label_elastisys_io_node_group!=""}, "instance", "$1", "node", "(.*)")) > {{.Values.capacityManagementAlertsNodeGroupMemoryLimit1h}}/100
      for: 5m
      labels:
        severity: warning
    - alert: NodeCPU{{.Values.capacityManagementAlertsNodeCpuLimit1h}}PercentOver1h
      annotations:
        message: CPU usage has been over {{.Values.capacityManagementAlertsNodeCpuLimit1h}}% on average over the span of 1h for the node {{`{{ $labels.instance }}`}} in Cluster {{`{{ $labels.cluster }}`}}.
        runbook_url: {{ .Values.runbookUrls.clusterCapacityManagement.NodeCPUXPercentOver1h }}
      expr: sum by (instance) (rate(node_cpu_seconds_total{mode!='idle',cluster=~".*"}[1h])) / on (instance) instance:node_num_cpu:sum * on (instance) group_left (label_elastisys_io_node_group,cluster) label_replace(kube_node_labels{label_elastisys_io_node_group!=""}, "instance", "$1", "node", "(.*)") > {{.Values.capacityManagementAlertsNodeCpuLimit1h}}/100
      for: 5m
      labels:
        severity: warning
    - alert: NodeMemory{{.Values.capacityManagementAlertsNodeMemoryLimit1h}}PercentOver1h
      annotations:
        message: Memory usage has been over {{.Values.capacityManagementAlertsNodeMemoryLimit1h}}% on average over the span of 1h for the Node {{`{{ $labels.instance }}`}} in Cluster {{`{{ $labels.cluster }}`}}.
        runbook_url: {{ .Values.runbookUrls.clusterCapacityManagement.NodeMemoryXPercentOver1h }}
      expr: |-
        (
          avg_over_time (instance:node_memory_utilisation:ratio{cluster=~".*"}[1h]) * on (instance) group_left (label_elastisys_io_node_group)
          label_replace(kube_node_labels{label_elastisys_io_node_group!=""}, "instance", "$1", "node", "(.*)")
        ) > {{.Values.capacityManagementAlertsNodeMemoryLimit1h}}/100
      for: 5m
      labels:
        severity: warning
    - alert: NodeGroupCpuRequest{{ .Values.capacityManagementAlertsCpuRequestLimit }}Percent
      annotations:
        message: Average CPU requests is over {{ .Values.capacityManagementAlertsCpuRequestLimit }}% in the Node Group {{`{{ $labels.label_elastisys_io_node_group }}`}} in Cluster {{`{{ $labels.cluster }}`}}.
        runbook_url: {{ .Values.runbookUrls.clusterCapacityManagement.NodeGroupCpuRequestXPercent }}
      expr: |-
        (
          avg by (label_elastisys_io_node_group,cluster) (sum by (node,cluster) (kube_pod_container_resource_requests{cluster=~".*",namespace=~".*",resource="cpu"}
        and
          on(pod, namespace, cluster) kube_pod_status_phase{cluster=~".*",namespace=~".*",phase="Running"} == 1)
        ) / (
          sum by(node,cluster) (kube_node_status_allocatable{cluster=~".*",resource="cpu"})) * on (node) group_left (label_elastisys_io_node_group)
          label_replace(kube_node_labels{label_elastisys_io_node_group!~'{{ .Values.capacityManagementAlertsRequestsExcludePattern }}'}, "instance", "$1", "node", "(.*)")
        ) >= {{ .Values.capacityManagementAlertsCpuRequestLimit }}/100
      for: 5m
      labels:
        severity: warning
    - alert: NodeGroupMemoryRequest{{ .Values.capacityManagementAlertsMemoryRequestLimit }}Percent
      annotations:
        message: Average memory requests is over {{ .Values.capacityManagementAlertsMemoryRequestLimit }}% in the Node Group {{`{{ $labels.label_elastisys_io_node_group }}`}} in Cluster {{`{{ $labels.cluster }}`}}.
        runbook_url: {{ .Values.runbookUrls.clusterCapacityManagement.NodeGroupMemoryRequestXPercent }}
      expr: |-
        (
          avg by (label_elastisys_io_node_group,cluster) (sum by (node,cluster) (kube_pod_container_resource_requests{cluster=~".*",namespace=~".*",resource="memory"}
        and
          on(pod, namespace, cluster) kube_pod_status_phase{cluster=~".*",namespace=~".*",phase="Running"} == 1)
        ) / (
          sum by(node,cluster) (kube_node_status_allocatable{cluster=~".*",resource="memory"})) * on (node) group_left (label_elastisys_io_node_group)
          label_replace(kube_node_labels{label_elastisys_io_node_group!~'{{ .Values.capacityManagementAlertsRequestsExcludePattern }}'}, "instance", "$1", "node", "(.*)")
        ) >= {{ .Values.capacityManagementAlertsMemoryRequestLimit }}/100
      for: 5m
      labels:
        severity: warning
    - alert: NodeMissingElastisysNodeGroupLabel
      annotations:
        description: "The node {{`{{`}} $labels.node {{`}}`}} in {{`{{`}} $labels.cluster {{`}}`}}  is missing the 'elastisys.io/node-group' label. This might affect capacity management monitoring."
        summary: "Node {{`{{`}} $labels.node {{`}}`}} in {{`{{`}} $labels.cluster {{`}}`}} is missing the  'elastisys.io/node-group' label."
      expr: |
        kube_node_labels{label_elastisys_io_node_group=""}
      for: 60m
      labels:
        severity: warning
{{- end }}
