# Found from https://github.com/thanos-io/thanos/blob/main/examples/alerts/alerts.yaml
# But edited to match our names for jobs, thanos-ruler section
groups:
- name: thanos-ruler
  rules:
  - alert: ThanosRuleIsDown
    annotations:
      description: ThanosRule has disappeared. Prometheus target for the component
        cannot be discovered.
      runbook_url: {{ .Values.runbookUrls.thanos.ThanosRuleIsDown }}
      summary: Thanos component has disappeared.
    expr: |
      absent(up{job=~".*thanos-receiver-ruler.*"} == 1)
    for: 5m
    labels:
      severity: critical
      group: Thanos
  - alert: ThanosRuleQueueIsDroppingAlerts
    annotations:
      description: Thanos Rule {{`{{$labels.instance}}`}} is failing to queue alerts.
      runbook_url: {{ .Values.runbookUrls.thanos.ThanosRuleQueueIsDroppingAlerts }}
      summary: Thanos Rule is failing to queue alerts.
    expr: |
      sum by (cluster, job, instance) (rate(thanos_alert_queue_alerts_dropped_total{job=~".*thanos-receiver-ruler.*"}[5m])) > 0
    for: 5m
    labels:
      severity: critical
      group: Thanos
  - alert: ThanosRuleSenderIsFailingAlerts
    annotations:
      description: Thanos Rule {{`{{$labels.instance}}`}} is failing to send alerts to alertmanager.
      runbook_url: {{ .Values.runbookUrls.thanos.ThanosRuleSenderIsFailingAlerts }}
      summary: Thanos Rule is failing to send alerts to alertmanager.
    expr: |
      sum by (cluster, job, instance) (rate(thanos_alert_sender_alerts_dropped_total{job=~".*thanos-receiver-ruler.*"}[5m])) > 0
    for: 5m
    labels:
      severity: critical
      group: Thanos
  - alert: ThanosRuleHighRuleEvaluationFailures
    annotations:
      description: Thanos Rule {{`{{$labels.instance}}`}} is failing to evaluate rules.
      runbook_url: {{ .Values.runbookUrls.thanos.ThanosRuleHighRuleEvaluationFailures }}
      summary: Thanos Rule is failing to evaluate rules.
    expr: |
      (
        sum by (cluster, job, instance) (rate(prometheus_rule_evaluation_failures_total{job=~".*thanos-receiver-ruler.*"}[5m]))
      /
        sum by (cluster, job, instance) (rate(prometheus_rule_evaluations_total{job=~".*thanos-receiver-ruler.*"}[5m]))
      * 100 > 5
      )
    for: 5m
    labels:
      severity: critical
      group: Thanos
  - alert: ThanosRuleHighRuleEvaluationWarnings
    annotations:
      description: Thanos Rule {{`{{$labels.instance}}`}} has high number of evaluation
        warnings.
      runbook_url: {{ .Values.runbookUrls.thanos.ThanosRuleHighRuleEvaluationWarnings }}
      summary: Thanos Rule has high number of evaluation warnings.
    expr: |
      sum by (cluster, job, instance) (rate(thanos_rule_evaluation_with_warnings_total{job=~".*thanos-receiver-ruler.*"}[5m])) > 0
    for: 15m
    labels:
      severity: info
      group: Thanos
  - alert: ThanosRuleRuleEvaluationLatencyHigh
    annotations:
      description: Thanos Rule {{`{{$labels.instance}}`}} has higher evaluation latency
        than interval for {{`{{$labels.rule_group}}`}}.
      runbook_url: {{ .Values.runbookUrls.thanos.ThanosRuleRuleEvaluationLatencyHigh }}
      summary: Thanos Rule has high rule evaluation latency.
    expr: |
      (
        sum by (cluster, job, instance, rule_group) (prometheus_rule_group_last_duration_seconds{job=~".*thanos-receiver-ruler.*"})
      >
        sum by (cluster, job, instance, rule_group) (prometheus_rule_group_interval_seconds{job=~".*thanos-receiver-ruler.*"})
      )
    for: 5m
    labels:
      severity: warning
      group: Thanos
  - alert: ThanosRuleGrpcErrorRate
    annotations:
      description: Thanos Rule {{`{{$labels.job}}`}} is failing to handle {{`{{$value | humanize}}`}}%
        of requests.
      runbook_url: {{ .Values.runbookUrls.thanos.ThanosRuleGrpcErrorRate }}
      summary: Thanos Rule is failing to handle grpc requests.
    expr: |
      (
        sum by (cluster, job, instance) (rate(grpc_server_handled_total{grpc_code=~"Unknown|ResourceExhausted|Internal|Unavailable|DataLoss|DeadlineExceeded", job=~".*thanos-receiver-ruler.*"}[5m]))
      /
        sum by (cluster, job, instance) (rate(grpc_server_started_total{job=~".*thanos-receiver-ruler.*"}[5m]))
      * 100 > 5
      )
    for: 5m
    labels:
      severity: warning
      group: Thanos
  - alert: ThanosRuleConfigReloadFailure
    annotations:
      description: Thanos Rule {{`{{$labels.job}}`}} has not been able to reload its configuration.
      runbook_url: {{ .Values.runbookUrls.thanos.ThanosRuleConfigReloadFailure }}
      summary: Thanos Rule has not been able to reload configuration.
    expr: avg by (cluster, job, instance) (thanos_rule_config_last_reload_successful{job=~".*thanos-receiver-ruler.*"})
      != 1
    for: 5m
    labels:
      severity: info
      group: Thanos
  - alert: ThanosRuleQueryHighDNSFailures
    annotations:
      description: Thanos Rule {{`{{$labels.job}}`}} has {{`{{$value | humanize}}`}}% of failing
        DNS queries for query endpoints.
      runbook_url: {{ .Values.runbookUrls.thanos.ThanosRuleQueryHighDNSFailures }}
      summary: Thanos Rule is having high number of DNS failures.
    expr: |
      (
        sum by (cluster, job, instance) (rate(thanos_rule_query_apis_dns_failures_total{job=~".*thanos-receiver-ruler.*"}[5m]))
      /
        sum by (cluster, job, instance) (rate(thanos_rule_query_apis_dns_lookups_total{job=~".*thanos-receiver-ruler.*"}[5m]))
      * 100 > 1
      )
    for: 15m
    labels:
      severity: warning
      group: Thanos
  - alert: ThanosRuleAlertmanagerHighDNSFailures
    annotations:
      description: Thanos Rule {{`{{$labels.instance}}`}} has {{`{{$value | humanize}}`}}% of
        failing DNS queries for Alertmanager endpoints.
      runbook_url: {{ .Values.runbookUrls.thanos.ThanosRuleAlertmanagerHighDNSFailures }}
      summary: Thanos Rule is having high number of DNS failures.
    expr: |
      (
        sum by (cluster, job, instance) (rate(thanos_rule_alertmanagers_dns_failures_total{job=~".*thanos-receiver-ruler.*"}[5m]))
      /
        sum by (cluster, job, instance) (rate(thanos_rule_alertmanagers_dns_lookups_total{job=~".*thanos-receiver-ruler.*"}[5m]))
      * 100 > 1
      )
    for: 15m
    labels:
      severity: warning
      group: Thanos
  - alert: ThanosRuleNoEvaluationFor10Intervals
    annotations:
      description: Thanos Rule {{`{{$labels.job}}`}} has {{`{{$value | humanize}}`}}% rule groups
        that did not evaluate for at least 10x of their expected interval.
      runbook_url: {{ .Values.runbookUrls.thanos.ThanosRuleNoEvaluationFor10Intervals }}
      summary: Thanos Rule has rule groups that did not evaluate for 10 intervals.
    expr: |
      time() -  max by (cluster, job, instance, group) (prometheus_rule_group_last_evaluation_timestamp_seconds{job=~".*thanos-receiver-ruler.*"})
      >
      10 * max by (cluster, job, instance, group) (prometheus_rule_group_interval_seconds{job=~".*thanos-receiver-ruler.*"})
    for: 5m
    labels:
      severity: info
      group: Thanos
  - alert: ThanosNoRuleEvaluations
    annotations:
      description: Thanos Rule {{`{{$labels.instance}}`}} did not perform any rule evaluations
        in the past 10 minutes.
      runbook_url: {{ .Values.runbookUrls.thanos.ThanosNoRuleEvaluations }}
      summary: Thanos Rule did not perform any rule evaluations.
    expr: |
      sum by (cluster, job, instance) (rate(prometheus_rule_evaluations_total{job=~".*thanos-receiver-ruler.*"}[5m])) <= 0
        and
      sum by (cluster, job, instance) (thanos_rule_loaded_rules{job=~".*thanos-receiver-ruler.*"}) > 0
    for: 5m
    labels:
      severity: critical
      group: Thanos
