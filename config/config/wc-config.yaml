# This configuration applies to the workload cluster.
# It will override settings set in "defaults/common-config.yaml".
global:
  ## The cluster name.
  ## Used in logs and metrics as to separate these from other clusters.
  clusterName: ${CK8S_ENVIRONMENT_NAME}-wc

## Nfs-client-provisioner configuration.
## Deployment is controlled via 'storageClasses.nfs.enabled'.
nfsProvisioner:
  server: ""
  path: /nfs
  resources:
    limits:
      cpu: 100m
      memory: 128Mi
    requests:
      cpu: 100m
      memory: 128Mi
  tolerations: []
  nodeSelector: {}
  affinity: {}

## User configuration.
user:
  ## This only controls if the namespaces should be created, user RBAC is always created.
  createNamespaces: true

  ## List of user namespaces to create.
  namespaces:
    - set-me
    - demo

  ## List of users to create RBAC rules for.
  adminUsers:
    - set-me
    - admin@example.com

  ## List of groups to create RBAC rules for.
  adminGroups:
    - set-me

## Falco configuration.
falco:
  enabled: true
  resources:
    limits:
      cpu: 200m
      memory: 1024Mi
    requests:
      cpu: 100m
      memory: 512Mi

  ## Run on master nodes.
  tolerations:
    - key: node-role.kubernetes.io/master
      effect: NoSchedule
  affinity: {}
  nodeSelector: {}

  ## Falco alerting configuration.
  alerts:
    enabled: true
    ## supported: 'alertmanager', 'slack'.
    type: alertmanager
    priority: notice
    hostPort: http://kube-prometheus-stack-alertmanager.monitoring:9093

  falcoSidekick:
    resources:
      limits:
        cpu: 20m
        memory: 50Mi
      requests:
        cpu: 10m
        memory: 25Mi
    tolerations: []
    affinity: {}
    nodeSelector: {}

  falcoExporter:
    resources:
      requests:
        cpu: 5m
        memory: 15Mi
      limits:
        cpu: 5m
        memory: 15Mi
    tolerations:
      - effect: NoSchedule
        key: node-role.kubernetes.io/master
    affinity: {}
    nodeSelector: {}

## Elasticsearch cluster topolgy.
## Used in prometheus alerts.
elasticsearch:
  subdomain: elastic
  masterNode:
    count: 1
  dataNode:
    count: 2
  clientNode:
    count: 1

## Prometheus configuration.
## Prometheus collects metrics and pushes it to InfluxDB.
prometheus:
  remoteWrite:
    ## User used when authentication against InfluxDB.
    user: wcWriter

  ## Additional prometheus scrape config.
  ## ref: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config
  additionalScrapeConfigs: []
  ## the percentage of use the resources are set to hit in 3 days
  predictLinearLimit: 66

## Open policy agent configuration
opa:
  enabled: true

  ## Enable rule that requires pods to come from
  ## the image registry defined by "URL".
  ## "enforcement" can assume either "dryrun" or "deny".
  imageRegistry:
    enabled: true
    enforcement: dryrun
    URL:
      - set-me
      - harbor.example.com
      ## Uncomment this if you want to add an OPA exception for cert-manager-acmesolver.
      ## This should be added only as an exception, e.g: if you cannot rely on a harbor instance managed by users.
      ## Otherwise set the correct repository for this image in the certmanager section.
      # - quay.io/jetstack/cert-manager-acmesolver

  ## Enable rule that requires pods to be targeted
  ## by at least one network policy.
  networkPolicies:
    enabled: true
    enforcement: dryrun

  ## Enable rule that requires pods to have resource requests.
  resourceRequests:
    enabled: true
    enforcement: dryrun

## Configuration for fluentd.
## Fluentd ships logs to elasticsearch.
## Consists of two different deployments, one for running on master nodes
## and and one for running on "user nodes".
fluentd:
  ## Tolerate master nodes.
  tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      value: ""

  ## Only run on master nodes.
  nodeSelector:
    node-role.kubernetes.io/master: ""

  resources:
    limits:
      cpu: 500m
      memory: 572Mi
    requests:
      cpu: 200m
      memory: 300Mi

  affinity: {}

  ## Extra fluentd config to mount.
  extraConfigMaps: {}

  ## User controllable fluentd deployment.
  ## These pods collect logs from nodes where the user can run pods.
  ## Users can specify additional plugins and config in the respective configmaps:
  ## 'fluentd-extra-plugins', and 'fluentd-extra-config'.
  user:
    resources:
      limits:
        cpu: 500m
        memory: 572Mi
      requests:
        cpu: 200m
        memory: 300Mi

    tolerations: []
    affinity: {}
    nodeSelector: {}

influxDB:
  subdomain: influxdb
