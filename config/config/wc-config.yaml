global:
  ck8sVersion: ${CK8S_VERSION}
  cloudProvider: ${CK8S_CLOUD_PROVIDER}
  clusterName: ${CK8S_ENVIRONMENT_NAME}-wc
  baseDomain: "set-me"
  opsDomain: "set-me"
  issuer: letsencrypt-staging
  verifyTls: true
  clusterDns: "10.43.0.10"

storageClasses:
  # Name of the default storageclass.
  # Normally one of 'nfs-client', 'cinder-storage', 'local-storage', 'ebs-gp2'.
  default: "set-me"

  nfs:
    enabled: null # true | false
  cinder:
    enabled: null # true | false
  local:
    enabled: null # true | false
  ebs:
    enabled: null # true | false

objectStorage:
  # Options are "s3", "gcs", or "none"
  # If "none", remember to disable backups (velero)
  type: "s3"
  # gcs:
  #   project: "set-me"
  # s3:
  #   region: "set-me"
  #   regionAddress: "set-me"
  #   regionEndpoint: "set-me"
  buckets:
    harbor: "${CK8S_ENVIRONMENT_NAME}-harbor"
    velero: "${CK8S_ENVIRONMENT_NAME}-velero"
    elasticsearch: "${CK8S_ENVIRONMENT_NAME}-es-backup"
    influxDB: "${CK8S_ENVIRONMENT_NAME}-influxdb"
    scFluentd: "${CK8S_ENVIRONMENT_NAME}-sc-logs"

user:
  namespaces:
    - demo
  adminUsers:
    - admin@example.com
  alertmanager:
    enabled: false
    namespace: monitoring
    ingress:
      enabled: false

falco:
  enabled: true
  resources:
    limits:
      cpu: 200m
      memory: 1024Mi
    requests:
      cpu: 100m
      memory: 512Mi
  tolerations:
    - key: "node-role.kubernetes.io/master"
      effect: "NoSchedule"
  affinity: {}
  nodeSelector: {}
  alerts:
    enabled: true
    # supported: alertmanager|slack
    type: alertmanager
    priority: notice
    hostPort: "http://kube-prometheus-stack-alertmanager.monitoring:9093"
    # if type=slack falco.alerts.slackWebhook must be set in the secrets yaml file
  falcoSidekick:
    resources:
      limits:
        cpu: 20m
        memory: 50Mi
      requests:
        cpu: 10m
        memory: 25Mi
    tolerations: []
    affinity: {}
    nodeSelector: {}

prometheus:
  remoteWrite:
    # Same as 'influxDB.users.wcWriter'.
    user: wcWriter
  storage:
    size: 5Gi
  retention:
    size: 4GiB
    age:  3d
  resources:
    requests:
      memory: 1Gi
      cpu: 300m
    limits:
      memory: 2Gi
      cpu: "1"
  tolerations: []
  affinity: {}
  nodeSelector: {}
  additionalScrapeConfigs: []

opa:
  enabled: true
  imageRegistry:
    enabled: true
    enforcement: dryrun
    URL: "harbor.set-me"
  networkPolicies:
    enabled: true
    enforcement: dryrun
  resourceRequests:
    enabled: true
    enforcement: dryrun

elasticsearch:
  masterNode:
    count: 1
  dataNode:
    count: 2
  clientNode:
    count: 1

fluentd:
  tolerations:
  - effect: NoSchedule
    key: "node-role.kubernetes.io/master"
    value: ""
  # Only run on control plane nodes
  nodeSelector:
    node-role.kubernetes.io/master: ""
  resources:
    limits:
      cpu: 200m
      memory: 500Mi
    requests:
      cpu: 200m
      memory: 500Mi
  affinity: {}
  extraConfigMaps: {}
  user:
    resources:
      limits:
        cpu: 200m
        memory: 500Mi
      requests:
        cpu: 200m
        memory: 500Mi
    tolerations: []
    affinity: {}
    nodeSelector: {}

ck8sdash:
  enabled: true
  tolerations: []
  affinity: {}
  nodeSelector: {}
  nginx:
    resources:
      requests:
        memory: 64Mi
        cpu: 50m
      limits:
        memory: 128Mi
        cpu: 100m
  server:
    resources:
      requests:
        memory: 64Mi
        cpu: 50m
      limits:
        memory: 128Mi
        cpu: 100m

externalTrafficPolicy:
  local: false
  whitelistRange:
    global: "0.0.0.0/0"
    ck8sdash: false

nfsProvisioner:
  server: ""
  path: /nfs
  resources:
    limits:
      cpu: 100m
      memory: 128Mi
    requests:
      cpu: 100m
      memory: 128Mi
  tolerations: []
  affinity: {}
  nodeSelector: {}

ingressNginx:
  controller:
  # Chart deploys correctly but does not work with resourceRequests
    resources: {}
      # limits:
      #   cpu: 100m
      #   memory: 64Mi
      # requests:
      #   cpu: 100m
      #   memory: 64Mi
    tolerations:
      - key: "nodeType"
        operator: "Exists"
        effect: "NoSchedule"
    affinity: {}
    nodeSelector: {}
    config:
      useProxyProtocol: "set-me"
    useHostPort: "set-me"
    service:
      enabled: "set-me"
      type: "set-me"
      annotations: "set-me"
    # Will add custom configuration options to Nginx https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/
    additionalConfig: {}

  defaultBackend:
  # Chart deploys correctly but does not work with resourceRequests
    resources: {}
      # limits:
      #   cpu: 100m
      #   memory: 64Mi
      # requests:
      #   cpu: 100m
      #   memory: 64Mi
    tolerations:
      - key: "nodeType"
        operator: "Equal"
        value: "elastisys"
        effect: "NoSchedule"
    affinity: {}
    nodeSelector: {}

velero:
  enabled: true
  tolerations: []
  nodeSelector: {}
  resources:
    limits:
      cpu: 200m
      memory: 200Mi
    requests:
      cpu: 100m
      memory: 100Mi
  restic:
    tolerations: []
    resources:
      limits:
        cpu: 200m
        memory: 200Mi
      requests:
        cpu: 100m
        memory: 100Mi

issuers:
  letsencrypt:
    enabled: true
    namespaces: []
    prod:
      email: "set-me"
    staging:
      email: "set-me"
  extraIssuers: []

certmanager:
  resources: {}
  nodeSelector: {}
  tolerations: {}
  affinity: {}

  webhook:
    resources: {}
    nodeSelector: {}
    tolerations: {}
    affinity: {}

  cainjector:
    resources: {}
    nodeSelector: {}
    tolerations: {}
    affinity: {}
