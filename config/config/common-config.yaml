## Common Kubernetes configuration options.
## This configuration applies to both service and workload clusters.

## Define resources requests and limits for single Pods.
## ref: https://kubernetes.io/docs/user-guide/compute-resources/
## resources: {}

## Node labels for Pod assignment
## ref: https://kubernetes.io/docs/user-guide/node-selection/
## nodeSelector: {}

## Tolerations for Pod assignment
## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
## tolerations: []

## Affinity for Pod assignment
## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity
## affinity: {}

## Some common options used in various helm charts.
##
global:
  ## Compliantkubernetes-apps version.
  ## Use version number if you are exactly at a release tag.
  ## Otherwise use full commit hash of current commit.
  ## 'any', can be used to disable this validation.
  ck8sVersion: ${CK8S_VERSION}
  ck8sCloudProvider: ${CK8S_CLOUD_PROVIDER}
  ck8sEnvironmentName: ${CK8S_ENVIRONMENT_NAME}
  ck8sFlavor: ${CK8S_FLAVOR}

  ## Domain intended for ingress usage in the workload cluster
  ## and to reach user facing services such as kibana, grafana, and harbor.
  ## E.g. with 'prod.domain.com', kibana is reached via 'kibana.prod.domain.com'.
  baseDomain: set-me

  ## Domain intended for ingress usage in the service cluster and to reach
  ## non-user facing services such as influxdb and elasticsearch.
  ## E.g. with 'ops.prod.domain.com', elasticsearch is reached via 'elastic.ops.prod.domain.com'.
  opsDomain: set-me

  ## Default cert-manager issuer to use for issuing certificates for ingresses.
  ## Normally one of 'letsencrypt-staging' or 'letsencrypt-prod'.
  issuer: letsencrypt-staging

  ## Verify ingress certificates
  verifyTls: true

  ## IP of the cluster DNS in kubernetes
  clusterDns: 10.233.0.3

## Configuration of storageclasses.
storageClasses:
  # Name of the default storageclass.
  # Normally one of 'nfs-client', 'cinder-csi', 'local-storage', 'ebs-gp2', "rook-ceph-block".
  default: set-me

  ## Enable deployment of nfsClientProvisioner
  ## Note, 'nfs-client' is installed as a deafult storageclass only if 'storageClasses.default: nfs-client'.
  nfs:
    enabled: set-me

  ## Enableds installation of 'cinder-storage' storageclass.
  cinder:
    enabled: set-me

  ## Enables deployment of local-volume-provisioner and installation of 'local-storage' storageclass.
  local:
    enabled: set-me

  ## Enables installation of 'ebs-gp2' storageclass.
  ebs:
    enabled: set-me

## Object storage configuration for backups.
objectStorage:
  ## Options are 's3', 'gcs', or 'none'
  ## If 'none', remember to disable backups (velero)
  # If "none", remember to disable features that depend on object storage:
  #   all backups (velero, harbor, influxdb, elasticsearch), sc logs (fluentd)
  #   Also set harbor persistence to "filesystem" or "swift"
  # Otherwise configure the features to match this type.
  type: set-me
  # gcs:
  #   project: set-me
  # s3:
  #   region: set-me
  #   regionEndpoint: set-me
  #   # Generally false when using AWS and Exoscale and true for other providers.
  #   forcePathStyle: set-me

  ## Buckets where each respctive application will store its backups.
  buckets:
    velero: ${CK8S_ENVIRONMENT_NAME}-velero

## User configuration.
user:
  ## User controlled alertmanager configuration.
  alertmanager:
    enabled: false

    ## Namespace in which to install alertmanager
    ## Ensure that the namespace is included in workload cluster 'user.namespaces' list.
    namespace: alertmanager

    ## Create basic-auth protected ingress to alertmanager
    ingress:
      enabled: false

## Prometheus configuration.
## Prometheus collects metrics and pushes it to InfluxDB.
prometheusOperator:
  resources:
    requests:
      cpu: 50m
      memory: 100Mi
    limits:
      cpu: 100m
      memory: 200Mi

prometheusNodeExporter:
  resources:
    requests:
      cpu: 5m
      memory: 25Mi
    limits:
      cpu: 10m
      memory: 50Mi

kubeStateMetrics:
  resources:
    requests:
      cpu: 5m
      memory: 25Mi
    limits:
      cpu: 10m
      memory: 50Mi

prometheus:
  ## Persistence for prometheus to store metrics and wal.
  storage:
    enabled: false
    size: 5Gi

  ## When prometheus should start to remove metrics from local storage.
  retention:
    size: 4GiB
    age: 3d

  resources:
    requests:
      memory: 1Gi
      cpu: 300m
    limits:
      memory: 2Gi
      cpu: "1" ## Must be a string (integers might be suported in newer versions)

  tolerations: []
  affinity: {}
  nodeSelector: {}

## Set external traffic policy to: "Local" to preserve source IP on
## providers supporting it
## Ref: https://kubernetes.io/docs/tutorials/services/source-ip/#source-ip-for-services-with-typeloadbalancer
externalTrafficPolicy:
  local: false

  ## Source IP range to allow.
  whitelistRange:
    global: 0.0.0.0/0

## Nginx ingress controller configuration
ingressNginx:
  controller:
    resources:
      requests:
        cpu: 100m
        memory: 263Mi
      limits:
        cpu: 200m
        memory: 512Mi
    tolerations: []
    affinity: {}
    nodeSelector: {}

    config:
      ## If 'true', use PROXY protocol
      ## ref: https://docs.nginx.com/nginx/admin-guide/load-balancer/using-proxy-protocol/
      useProxyProtocol: set-me

    ## If 'true', nginx will use host ports 80 and 443
    useHostPort: set-me

    ## Kubernetes service configuration.
    service:
      enabled: set-me

      ## Type of service.
      ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types
      type: set-me

      ## Annotations to add to service
      ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
      annotations: set-me

    ## Additional configuration options for Nginx
    ## ref: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/
    additionalConfig: {}

  defaultBackend:
    resources:
      requests:
        cpu: 5m
        memory: 10Mi
      limits:
        cpu: 10m
        memory: 20Mi
    tolerations: []
    affinity: {}
    nodeSelector: {}

## Configration for Velero and Restic.
## Check out https://compliantkubernetes.io/user-guide/backup/ to see what's included in backups.
velero:
  enabled: true
  tolerations: []
  nodeSelector: {}
  schedule: 0 0 * * * # once per day
  resources:
    limits:
      cpu: 500m
      memory: 500Mi
    requests:
      cpu: 50m
      memory: 100Mi

  restic:
    tolerations: []
    resources:
      limits:
        cpu: 500m
        memory: 500Mi
      requests:
        cpu: 50m
        memory: 100Mi

## Configuration for cert-manager issuers.
issuers:
  ## Deploy let's encrypt ACME issuers
  ## "letsencrypt-prod" and "letsencrypt-staging".
  letsencrypt:
    enabled: true
    prod:
      ## Mail through which letsencrypt can contact you.
      email: set-me
    staging:
      ## Mail through which letsencrypt can contact you.
      email: set-me

  ## Additional issuers to create.
  ## ref: https://cert-manager.io/docs/configuration/
  extraIssuers: []
  # - apiVersion: cert-manager.io/v1
  #   kind: Issuer
  #   metadata:
  #     name: selfsigned-issuer
  #     namespace: sandbox
  #   spec:
  #     selfSigned: {}

## Configration for cert-manager and it's components.
certmanager:
  resources:
    requests:
      cpu: 25m
      memory: 100Mi
    limits:
      cpu: 250m
      memory: 250Mi
  nodeSelector: {}
  tolerations: {}
  affinity: {}

  ## when using cert-manager with HTTP01 challenge and a custom image registry the below parameter should be added in the extraArgs
  ## !! this works only with public repositories !! see https://github.com/jetstack/cert-manager/issues/2429
  ## update the image tag based on the version used in the helm chart
  ## - --acme-http01-solver-image=<harbor_server_name>/<proxy_project_name>/jetstack/cert-manager-acmesolver:v1.4.0
  extraArgs: []

  webhook:
    resources:
      requests:
        cpu: 25m
        memory: 25Mi
      limits:
        cpu: 250m
        memory: 250Mi
    nodeSelector: {}
    tolerations: {}
    affinity: {}

  cainjector:
    resources:
      requests:
        cpu: 25m
        memory: 100Mi
      limits:
        cpu: 250m
        memory: 250Mi
    nodeSelector: {}
    tolerations: {}
    affinity: {}

## Configuration for metric-server
metricsServer:
  enabled: true
  resources:
    requests:
      cpu: 10m
      memory: 25Mi
    limits:
      cpu: 100m
      memory: 100Mi

calicoAccountant:
  enabled: true

calicoFelixMetrics:
  enabled: true

clusterAdmin:
  users:
    - set-me
    - admin@example.com
  groups: []

starboard:
  resources:
    requests:
      cpu: 5m
      memory: 50Mi
    limits:
      cpu: 10m
      memory: 128Mi
  tolerations: []
  affinity: {}

vulnerabilityExporter:
  resources:
    requests:
      cpu: 20m
      memory: 15Mi
    limits:
      cpu: 40m
      memory: 30Mi
  tolerations: []
  affinity: {}

  curlcronjob:
    resources:
      requests:
        cpu: 20m
        memory: 64Mi
      limits:
        cpu: 40m
        memory: 128Mi

monitoring:
  rook:
    enabled: false
